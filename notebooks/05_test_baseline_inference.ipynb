{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Baseline Inference Engine\n",
        "\n",
        "This notebook tests the baseline LLM inference on sample data.\n",
        "\n",
        "**Tests:**\n",
        "1. Load baseline model\n",
        "2. Run inference on sample data\n",
        "3. Display predictions vs ground truth\n",
        "4. Compute basic metrics\n",
        "\n",
        "**Expected Output:**\n",
        "- Model loads successfully\n",
        "- Predictions generated for all samples\n",
        "- Metrics computed (accuracy, per-class stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/amin/miniconda3/envs/temp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Imports successful\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.baselines.llama_single import LlamaSingleBaseline\n",
        "from src.evaluation.metrics import compute_all_metrics, print_metrics_report\n",
        "from src.utils.preprocess import load_from_jsonl\n",
        "import yaml\n",
        "import torch\n",
        "\n",
        "print(\"✅ Imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Configuration:\n",
            "  Model: meta-llama/Llama-3.1-8B-Instruct\n",
            "  Dtype: bf16\n",
            "  4-bit: False\n",
            "  Max tokens: 8\n",
            "  Temperature: 0.1\n",
            "  Prompt template: status_v1\n"
          ]
        }
      ],
      "source": [
        "# Load baseline config\n",
        "config_path = project_root / 'configs' / 'baseline.yaml'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Baseline Configuration:\")\n",
        "print(f\"  Model: {config['model_name']}\")\n",
        "print(f\"  Dtype: {config['dtype']}\")\n",
        "print(f\"  4-bit: {config['load_in_4bit']}\")\n",
        "print(f\"  Max tokens: {config['max_new_tokens']}\")\n",
        "print(f\"  Temperature: {config['temperature']}\")\n",
        "print(f\"  Prompt template: {config['prompt_template']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Check GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "Device: NVIDIA GeForce RTX 4090\n",
            "Total GPU memory: 25.3 GB\n",
            "Currently allocated: 0.00 GB\n"
          ]
        }
      ],
      "source": [
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(f\"Currently allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Baseline Model\n",
        "\n",
        "This will take ~30-60 seconds to load the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer from meta-llama/Llama-3.1-8B-Instruct...\n",
            "Loading model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully\n",
            "\n",
            "GPU Memory after loading:\n",
            "  Allocated: 7.16 GB\n",
            "  Reserved: 7.22 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "baseline = LlamaSingleBaseline(config)\n",
        "baseline.load_model()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\nGPU Memory after loading:\")\n",
        "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "    print(f\"  Reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Sample Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training samples: 3004\n",
            "\n",
            "Testing on 10 samples\n"
          ]
        }
      ],
      "source": [
        "# Load processed training data\n",
        "data_path = project_root / 'data' / 'processed' / 'train.jsonl'\n",
        "\n",
        "all_samples = load_from_jsonl(data_path)\n",
        "print(f\"Total training samples: {len(all_samples)}\")\n",
        "\n",
        "# Take 10 samples for testing\n",
        "n_samples = 10\n",
        "samples = all_samples[:n_samples]\n",
        "print(f\"\\nTesting on {len(samples)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Display Sample Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 1:\n",
            "  Text: Social History: Tob (-), EtOH - a glass of wine 1-2x/month, IVDU (-), lives with her husband and 9yr old daughter, does not work outside of the home....\n",
            "  Trigger: IVDU\n",
            "  True label: none\n",
            "  Source: mimic\n",
            "\n",
            "Sample 2:\n",
            "  Text: SOCIAL HISTORY: Former real estate [**Doctor Last Name 360**], current unemployed. Lives alone. Smokes 1-1.5 packs per day x20 years. Currently admits...\n",
            "  Trigger: IV drug use\n",
            "  True label: none\n",
            "  Source: mimic\n"
          ]
        }
      ],
      "source": [
        "print(\"Sample 1:\")\n",
        "print(f\"  Text: {samples[0]['text'][:150]}...\")\n",
        "print(f\"  Trigger: {samples[0]['trigger_text']}\")\n",
        "print(f\"  True label: {samples[0]['status_label']}\")\n",
        "print(f\"  Source: {samples[0]['source']}\")\n",
        "\n",
        "print(\"\\nSample 2:\")\n",
        "print(f\"  Text: {samples[1]['text'][:150]}...\")\n",
        "print(f\"  Trigger: {samples[1]['trigger_text']}\")\n",
        "print(f\"  True label: {samples[1]['status_label']}\")\n",
        "print(f\"  Source: {samples[1]['source']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Baseline Inference\n",
        "\n",
        "This will take ~2-3 seconds per sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 10%|█         | 1/10 [00:00<00:05,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 20%|██        | 2/10 [00:00<00:02,  2.72it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 40%|████      | 4/10 [00:00<00:01,  5.52it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 60%|██████    | 6/10 [00:01<00:00,  7.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            " 80%|████████  | 8/10 [00:01<00:00,  8.29it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "100%|██████████| 10/10 [00:01<00:00,  6.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Inference completed on 10 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results = baseline.predict_batch(samples, show_progress=True)\n",
        "print(f\"\\n✅ Inference completed on {len(results)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Display Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample 1:\n",
            "  Text: Social History: Tob (-), EtOH - a glass of wine 1-2x/month, IVDU (-), lives with her husband and 9yr...\n",
            "  Trigger: IVDU\n",
            "  True: none\n",
            "  Pred: current (b)\n",
            "  ❌\n",
            "\n",
            "Sample 2:\n",
            "  Text: SOCIAL HISTORY: Former real estate [**Doctor Last Name 360**], current unemployed. Lives alone. Smok...\n",
            "  Trigger: IV drug use\n",
            "  True: none\n",
            "  Pred: Not Applicable (d)\n",
            "  ❌\n",
            "\n",
            "Sample 3:\n",
            "  Text: SOCIAL HISTORY: Former real estate [**Doctor Last Name 360**], current unemployed. Lives alone. Smok...\n",
            "  Trigger: recreational drug use\n",
            "  True: none\n",
            "  Pred: current (b)\n",
            "  ❌\n",
            "\n",
            "Sample 4:\n",
            "  Text: Social History: No tobacco history. Denies excessive ETOH. Married with children. Works at the [**Co...\n",
            "  Trigger: recreatinal drugs\n",
            "  True: none\n",
            "  Pred: current (b)\n",
            "  ❌\n",
            "\n",
            "Sample 5:\n",
            "  Text: Social History: IVDA and illicit drug use (heroin, oxycontin, and cocaine) up until day of surgery. ...\n",
            "  Trigger: IVDA and illicit drug use\n",
            "  True: current\n",
            "  Pred: current (b)\n",
            "  ✅\n",
            "\n",
            "Sample 6:\n",
            "  Text: Social History: Pt lives at home with his wife. His daughter and grandson live downstairs in the sam...\n",
            "  Trigger: other drug use\n",
            "  True: none\n",
            "  Pred: Not Applicable (d)\n",
            "  ❌\n",
            "\n",
            "Sample 7:\n",
            "  Text: Social History: smokes 1 ppd, 60 PY hx, occa etoh, no drugs, worked as engineer w/ GE, lives w/ 44 y...\n",
            "  Trigger: drugs\n",
            "  True: none\n",
            "  Pred: current (b)\n",
            "  ❌\n",
            "\n",
            "Sample 8:\n",
            "  Text: Social History: Patient is widowed & lives alone. She has 6 children. -Tobacco history: None -ETOH: ...\n",
            "  Trigger: Illicit drugs\n",
            "  True: none\n",
            "  Pred: Not Applicable (d)\n",
            "  ❌\n",
            "\n",
            "Sample 9:\n",
            "  Text: Social History: Patient is divorced. He has two kids aged 16 and 14. He is from [**State 350**] and ...\n",
            "  Trigger: cocaine\n",
            "  True: current\n",
            "  Pred: Not Applicable (d)\n",
            "  ❌\n",
            "\n",
            "Sample 10:\n",
            "  Text: Social History: Retd. Lives with wife in TN, quit smoking 25 years ago, about 30 pack years before t...\n",
            "  Trigger: drugs\n",
            "  True: none\n",
            "  Pred: none (a)\n",
            "  ✅\n",
            "\n",
            "================================================================================\n",
            "Quick Accuracy: 2/10 = 20.0%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "\n",
        "for i, result in enumerate(results, 1):\n",
        "    true_label = result['status_label']\n",
        "    pred_label = result['pred_label']\n",
        "    pred_letter = result['pred_letter']\n",
        "    match = \"✅\" if true_label == pred_label else \"❌\"\n",
        "    \n",
        "    if true_label == pred_label:\n",
        "        correct += 1\n",
        "    \n",
        "    print(f\"\\nSample {i}:\")\n",
        "    print(f\"  Text: {result['text'][:100]}...\")\n",
        "    print(f\"  Trigger: {result['trigger_text']}\")\n",
        "    print(f\"  True: {true_label}\")\n",
        "    print(f\"  Pred: {pred_label} ({pred_letter})\")\n",
        "    print(f\"  {match}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Quick Accuracy: {correct}/{len(results)} = {correct/len(results):.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Compute Detailed Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EVALUATION METRICS\n",
            "================================================================================\n",
            "\n",
            "Overall Metrics:\n",
            "  Accuracy: 0.2000\n",
            "  FPR (False Positive Rate for 'none'): 0.0000\n",
            "  Total Samples: 10\n",
            "\n",
            "Label Distribution (Ground Truth):\n",
            "  current             :     2 ( 20.0%)\n",
            "  none                :     8 ( 80.0%)\n",
            "\n",
            "Label Distribution (Predicted):\n",
            "  Not Applicable      :     4 ( 40.0%)\n",
            "  current             :     5 ( 50.0%)\n",
            "  none                :     1 ( 10.0%)\n",
            "\n",
            "Per-Class Metrics:\n",
            "Label                  Prec    Rec     F1   Supp\n",
            "--------------------------------------------------\n",
            "none                  1.000  0.125  0.222      8\n",
            "current               0.200  0.500  0.286      2\n",
            "past                  0.000  0.000  0.000      0\n",
            "Not Applicable        0.000  0.000  0.000      0\n",
            "\n",
            "Confusion Matrix:\n",
            "True \\ Pred               none   current      pastNot Applic\n",
            "------------------------------------------------------------\n",
            "none                         1         4         0         3\n",
            "current                      0         1         0         1\n",
            "past                         0         0         0         0\n",
            "Not Applicable               0         0         0         0\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "y_true = [r['status_label'] for r in results]\n",
        "y_pred = [r['pred_label'] for r in results]\n",
        "\n",
        "labels = ['none', 'current', 'past', 'Not Applicable']\n",
        "metrics = compute_all_metrics(y_true, y_pred, labels=labels)\n",
        "\n",
        "print_metrics_report(metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Validation Checklist\n",
        "\n",
        "✅ **Check these:**\n",
        "1. Model loads without errors\n",
        "2. GPU memory usage is reasonable (< 10GB for bf16)\n",
        "3. Inference completes for all samples\n",
        "4. Predictions are valid labels (none/current/past/Not Applicable)\n",
        "5. Some predictions match ground truth (>0% accuracy)\n",
        "6. Confusion matrix makes sense (no all-zero rows/columns)\n",
        "\n",
        "**Expected Performance (baseline, untrained):**\n",
        "- Accuracy: Variable, typically 20-50% on small samples\n",
        "- FPR: May be high (50-100% on small samples)\n",
        "  - FPR measures: predicted drug use (current/past) when truth is no use (none/Not Applicable)\n",
        "  - Computed ONLY on negative ground truth samples\n",
        "  - Lower is better (target: <15% for safety)\n",
        "- This is expected - we'll improve it with the agentic approach!\n",
        "\n",
        "**Understanding FPR:**\n",
        "```\n",
        "Negative class (no drug use): none + Not Applicable\n",
        "Positive class (drug use): current + past\n",
        "\n",
        "FPR = FP / (FP + TN)\n",
        "FP = predicted positive when truth is negative\n",
        "TN = predicted negative when truth is negative\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**If all checks pass, proceed to Phase 3!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "temp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
