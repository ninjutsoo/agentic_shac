# Baseline model configuration for Drug StatusTime classification

model_name: "meta-llama/Meta-Llama-3.1-8B-Instruct"
dtype: "bf16"           # Set load_in_4bit: true for 24 GB GPUs
load_in_4bit: false
max_new_tokens: 8
temperature: 0.1
top_p: 0.9
batch_size: 8
prompt_template: "status_v1"

# Device configuration
device: "cuda"          # Will use GPU if available

